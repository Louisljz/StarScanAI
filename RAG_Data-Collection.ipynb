{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all PDF Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.nasa.gov/wp-content/uploads/2015/04/tb-23-06-091923.pdf', 'https://ntrs.nasa.gov/api/citations/20230010417/downloads/TB_23-05_080123%20FINAL.pdf', 'https://ntrs.nasa.gov/api/citations/20230010411/downloads/TB_23-04_r071923_NRB.pdf', 'https://ntrs.nasa.gov/api/citations/20230010357/downloads/TB_23-03v3.pdf', 'https://ntrs.nasa.gov/api/citations/20230001890/downloads/TB_23-02_Safety_031723.pdf', 'https://ntrs.nasa.gov/api/citations/20230001889/downloads/TB_23-01_Pyro%20Best%20Practices_031523.pdf', 'https://ntrs.nasa.gov/api/citations/20220013364/downloads/TB_22-08_Contaminant%20Reduction_083022-FINAL.pdf', 'https://ntrs.nasa.gov/api/citations/20220012296/downloads/TB_22-07_Helium%20Solubility_080922-Final.pdf', 'https://ntrs.nasa.gov/api/citations/20220011709/downloads/TB_22-06_SloshDynamics_080522.pdf', 'https://ntrs.nasa.gov/api/citations/20220011631/downloads/TB_22-05_Margin%20Reductions_080122v5.pdf', 'https://ntrs.nasa.gov/api/citations/20220010362/downloads/TB_22-04_Uncertainty%20Quantification_072822.pdf', 'https://ntrs.nasa.gov/api/citations/20220006583/downloads/TB_22-03_transient%20pressure_052022.pdf', 'https://ntrs.nasa.gov/api/citations/20220004167/downloads/TB_22-02_Filtration%20Standards-Final.pdf', 'https://ntrs.nasa.gov/api/citations/20220004162/downloads/TB_22-01_Detecting%20Flow-Induced%20Vibration%20in%20Bellows-Final.pdf', 'https://www.nasa.gov/wp-content/uploads/2023/09/tb-21-05-arecibo-failure-analysis-080221-final.pdf', 'https://www.nasa.gov/wp-content/uploads/2023/09/tb-21-04-copv-life-073021.pdf', 'https://ntrs.nasa.gov/api/citations/20210017830/downloads/TB_21-03-1_Hydrazine_032522.pdf', 'https://ntrs.nasa.gov/api/citations/20210014768/downloads/GenesisFlightMechanics_042721v2.pdf', 'https://ntrs.nasa.gov/api/citations/20210010461/downloads/TB_21-01_cavitation_022221.pdf', 'https://ntrs.nasa.gov/api/citations/20205007928/downloads/TB_20-08_ketezine_v6.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/techbul-20-07-bondline-strain-spikes-in-copvs-9-18-2020.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/techbul-20-06-material-compatibility-assessment-for-spacecraft-oxidizer-systems-final.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/tb-20-05-051823.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/tb-20-04-051823.pdf', 'https://ntrs.nasa.gov/api/citations/20205000801/downloads/NESC%20Technical%20Bulletin%2020-03%2C%20Navigation%20Filter%20Design%20Best%20Practices.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/techbul-20-02.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/techbul-20-01.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/techbul-19-02-0.pdf', 'https://ntrs.nasa.gov/api/citations/20210024100/downloads/TechBul_19-01-01%20Final.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/techbul-17-01-rev3.pdf', 'https://standards.nasa.gov/sites/default/files/standards/MSFC/Baseline/0/msfc-std-3716.pdf', 'https://standards.nasa.gov/sites/default/files/standards/MSFC/Baseline/0/msfc-spec-3717.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesc-tb-16-02-damage-tolerance-life-issues-in-copvs-with-thin-liners.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesc-tb-16-01-buckling-knockdown-factors-for-composite-cylinders.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesc-tb-15-03-best-practices-for-use-of-sine-vibration-testing.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesc-tb-15-02-best-practices-for-use-of-sine-burst-testing.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesc-tb-15-01-preventing-incorrect-installation-of-polarized-capacitors.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesc-tb-14-03-copv-mechanical-model-validation.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctb14-02-aerodynamic-rcs-orientation-and-jet-interaction-model-validation.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctb14-01-designing-for-flight-through-periods-of-instability.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/671748main-nesctb12-02-structuralanalysesandmarginsofsafety.pdf', 'https://ntrs.nasa.gov/api/citations/20100040272/downloads/20100040272.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/513040main-nesctb11-01nickelhydrogencpv-final.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/483905main-nesctechbul10-02pyrovalve-1.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/483905main-nesctechbul10-02pyrovalve-1.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/483905main-nesctechbul10-02pyrovalve.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctechbulscog09-05final.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctechbul09-04-penetrantnde.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctb09-03-liionbatteryguidelines.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctb09-02-liionbatterylimitations.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/nesctb09-01-pyrovalves.pdf', 'https://www.nasa.gov/wp-content/uploads/2015/04/182750main-nesctechbulletin07-07.pdf']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_pdf_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    pdf_links = []\n",
    "    \n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        if a_tag['href'].endswith('.pdf'):\n",
    "            pdf_links.append(a_tag['href'])\n",
    "    \n",
    "    return pdf_links\n",
    "\n",
    "url = \"https://www.nasa.gov/nesc/knowledge-products/nesc-technical-bulletins/\"\n",
    "pdf_links = get_pdf_links(url)\n",
    "pdf_links.remove('https://www.nasa.gov/wp-content/uploads/2023/10/tb-summary-100223.pdf')\n",
    "print(pdf_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFium2Loader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading PDFs: 100%|██████████| 52/52 [03:24<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for pdf_url in tqdm(pdf_links, desc=\"Loading PDFs\"):\n",
    "    retries = 3  # Number of retries\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            pdf_loader = PyPDFium2Loader(pdf_url)\n",
    "            pdf_chunks = pdf_loader.load_and_split(RecursiveCharacterTextSplitter(\n",
    "                                                chunk_size=1000, chunk_overlap=0))\n",
    "            # Extend documents with chunks and their source\n",
    "            for chunk in pdf_chunks:\n",
    "                documents.append({\n",
    "                    'text': chunk.page_content,\n",
    "                    'source': pdf_url\n",
    "                })\n",
    "            break  # If successful, break out of the retry loop\n",
    "        \n",
    "        except:  \n",
    "            if attempt < retries - 1:  # Don't sleep after the last attempt\n",
    "                time.sleep(5)  # Waits for 5 seconds if connection is aborted.\n",
    "            else:\n",
    "                print(f\"Failed to fetch {pdf_url} after {retries} attempts.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Embeddings and Push to Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2 doc embeddings, each with a dimensionality of 384.\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_model.embed_documents([doc['text'] for doc in documents[:2]])\n",
    "print(f\"We have {len(embeddings)} doc embeddings, each with \"\n",
    "      f\"a dimensionality of {len(embeddings[0])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.environ['pinecone_apikey'],\n",
    "    environment=os.environ['pinecone_env']\n",
    ")\n",
    "\n",
    "index_name = \"nasa-rag\"\n",
    "# First, check if our index already exists. If it doesn't, we create it\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "      name=index_name,\n",
    "      metric='cosine',\n",
    "      dimension=len(embeddings[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 30/30 [03:12<00:00,  6.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.00832,\n",
       " 'namespaces': {'': {'vector_count': 832}},\n",
       " 'total_vector_count': 832}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    texts = [doc['text'] for doc in batch]\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    ids = [str(i) for i in range(batch_start, batch_start + len(batch))]\n",
    "    \n",
    "    return ids, embeds\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Wrap the range with tqdm for progress bar\n",
    "for batch_start in tqdm(range(0, len(documents), batch_size), desc=\"Processing batches\"):\n",
    "    batch = documents[batch_start:batch_start + batch_size]\n",
    "    ids, embeds = process_batch(batch)\n",
    "    \n",
    "    index.upsert(vectors=zip(ids, embeds, batch))\n",
    "\n",
    "index.describe_index_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LLM+RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\NLP\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=os.environ['openai_apikey'])\n",
    "\n",
    "text_field = 'text'  # field in metadata that contains text content\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")\n",
    "\n",
    "rag_model = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The HPV Method for UQ is a method for modeling uncertainty in a structural dynamics system which combines a parametric variation of the HCB FI modal frequencies with a NPV method that randomly varies the HCB mass and stiffness matrices. The NPV component of the HPV method replaces the HCB matrices with an ensemble of random matrices based on RMT, which are real, symmetric, and possess the appropriate sign definiteness to represent structural mass, stiffness, or damping matrices. The HPV method uses uncertainty models for HCB components based on component modal test/analysis correlation results, and the NPV based dispersion of the HCB mass matrix is derived from the test self-orthogonality matrix.\n"
     ]
    }
   ],
   "source": [
    "response = rag_model('Explain The HPV Method for UQ')\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe HPV Method is a statistical technique used for Uncertainty Quantification (UQ). It is a Monte Carlo simulation-based method which combines the concepts of sensitivity analysis and probability distribution of model input uncertainty. The HPV Method uses a combination of Latin hypercube sampling and Monte Carlo simulation to generate a large number of model input combinations. The output of each model run is then analyzed to estimate the probability density function of the model output. The HPV Method is used to identify and understand the sources of input uncertainty that have the greatest impact on the model output. It is also used to identify and quantify the range of possible output values for a given set of model inputs.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('Explain The HPV Method for UQ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
